{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias only model \n",
    " - Write down code for the gradient equations\n",
    " - Use gradient descent library to optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/cnogueira/Documents/Development/Notebooks/study/week2/amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(path, 'rt', encoding=\"utf8\")\n",
    "header = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = header.strip().split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for line in f: \n",
    "    fields = line.strip().split('\\t')\n",
    "    d = dict(zip(header, fields))\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d['helpful_votes'] = int(d['helpful_votes'])\n",
    "    d['total_votes'] = int(d['total_votes'])\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here i am creating two data structures:  \n",
    "#For each user, which itens did they consume (users per item), and\n",
    "#For each items, which users consumed that item (item per user)\n",
    "usersPerItem = defaultdict(set) #Ui\n",
    "itemsPerUser = defaultdict(set) #Iu\n",
    "itemNames = {}\n",
    "for d in dataset:\n",
    "    user, item = d['customer_id'], d['product_id']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    itemNames[item] = d['product_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "for d in dataset:\n",
    "    user, item = d['customer_id'], d['product_id']\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(dataset)\n",
    "nUsers = len(reviewsPerUser)\n",
    "nItems = len(reviewsPerItem)\n",
    "users = list(reviewsPerUser.keys())\n",
    "items = list(reviewsPerItem.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just to see if the algorithm is better to just predict the mean in terms of mean square error all the time\n",
    "ratingMean = sum([d['star_rating'] for d in dataset])/len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting\n",
    "    - Alpha and Betau/Betai (userbiases) are the parameters I will fit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial value of alpha is the mean reating to help the algo to convert qickly\n",
    "alpha = ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial valie of betai and betau is zerp\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prediction function is just the bias only model\n",
    "def prediction(user, item):\n",
    "    return alpha + userBiases[user] + itemBiases[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack function\n",
    "# The gradient descent library expects a single vector of parameters (theta) \n",
    "# On this function I am unpacking back to produce alpha and betau and betai\n",
    "\n",
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0] # Alpha is the first position on the vector\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1])) \n",
    "    # Start on position 1 and go until the rest of the users onwards to the rest of that vector\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function is also required by the library (is written on the notes)\n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [predictions(d['customer_id'], d['product_id']) for d in dataset]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
