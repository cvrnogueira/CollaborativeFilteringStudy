{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias only model \n",
    " - Write down code for the gradient equations\n",
    " - Use gradient descent library to optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy\n",
    "import scipy.optimize\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/cnogueira/Documents/Development/Notebooks/study/week2/amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(path, 'rt', encoding=\"utf8\")\n",
    "header = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = header.strip().split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for line in f: \n",
    "    fields = line.strip().split('\\t')\n",
    "    d = dict(zip(header, fields))\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d['helpful_votes'] = int(d['helpful_votes'])\n",
    "    d['total_votes'] = int(d['total_votes'])\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here i am creating two data structures:  \n",
    "#For each user, which itens did they consume (users per item), and\n",
    "#For each items, which users consumed that item (item per user)\n",
    "usersPerItem = defaultdict(set) #Ui\n",
    "itemsPerUser = defaultdict(set) #Iu\n",
    "itemNames = {}\n",
    "for d in dataset:\n",
    "    user, item = d['customer_id'], d['product_id']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    itemNames[item] = d['product_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "for d in dataset:\n",
    "    user, item = d['customer_id'], d['product_id']\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(dataset)\n",
    "nUsers = len(reviewsPerUser)\n",
    "nItems = len(reviewsPerItem)\n",
    "users = list(reviewsPerUser.keys())\n",
    "items = list(reviewsPerItem.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just to see if the algorithm is better to just predict the mean in terms of mean square error all the time\n",
    "ratingMean = sum([d['star_rating'] for d in dataset])/len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting\n",
    "    - Alpha and Betau/Betai (userbiases) are the parameters I will fit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial value of alpha is the mean reating to help the algo to convert qickly\n",
    "alpha = ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial valie of betai and betau is zerp\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each user u have a vector of parameters saying \"What are the preference dimensions for that user u?\"\n",
    "# Each item i have a vector of parameters saying \"What are the properties of those items?\"\n",
    "userGamma = {}\n",
    "itemGamma = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set latent factors dimensionality to be 2 (simple model)\n",
    "K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in reviewsPerUser:\n",
    "    userGamma[u] = [random.random() * 0.1 - 0.05 for k in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reviewsPerItem:\n",
    "    itemGamma[i] = [random.random() * 0.1 - 0.05 for k in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner(x, y):\n",
    "    return sum([a*b for a,b in zip(x, y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prediction function is just the bias only model\n",
    "def prediction(user, item):\n",
    "    return alpha + userBiases[user] + itemBiases[item] + inner(userGamma[user], itemGamma[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack function\n",
    "\n",
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    global userGamma\n",
    "    global itemGamma\n",
    "    index = 0\n",
    "    alpha = theta[0] # Alpha is the first position on the vector\n",
    "    index = index + 1\n",
    "    userBiases = dict(zip(users, theta[index:nUsers+index])) \n",
    "    index += nUsers\n",
    "    itemBiases = dict(zip(items, theta[index:index+nItems]))\n",
    "    index+= nItems\n",
    "    for u in users:\n",
    "        userGamma[u] = theta[index:index+K]\n",
    "        index +=K\n",
    "    for i in items:\n",
    "        itemGamma[i] = theta[index:index+K]\n",
    "        index+= K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function is also required by the library (is written on the notes)\n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta) # extract alpha, betai, betau\n",
    "    # Use those values to make predictions in the datapoints on the training set\n",
    "    predictions = [prediction(d['customer_id'], d['product_id']) for d in dataset]\n",
    "    cost = MSE(predictions, labels)\n",
    "    # Debugging\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    # Regularization\n",
    "    for u in users:\n",
    "        cost *= lamb*userBiases[u]**2\n",
    "        for k in range(K):\n",
    "            cost +=lamb*userGamma[u][k]**2\n",
    "    for i in items:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "        for k in range(K):\n",
    "            cost += lamb*itemGamma[i][k]**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivative function has a corresponding derivative term for each parameter\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta) # have alpha, betau for each user and betai for each item\n",
    "    N =  len(dataset)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    dUserGamma = {}\n",
    "    dItemGamma = {}\n",
    "    for u in reviewsPerUser:\n",
    "        dUserGamma[u] = [0.0 for k in range(K)]\n",
    "    for i in reviewsPerItem:\n",
    "        dItemGamma[i] = [0.0 for k in range(K)]\n",
    "    for d in dataset:\n",
    "        u,i = d['customer_id'], d['product_id']\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - d['star_rating']\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] +=  2/N*diff\n",
    "        dItemBiases[u] +=  2/N*diff\n",
    "        for k in range(K):\n",
    "            dUserGamma[u][k] += 2/N*itemGamma[i][k]*diff\n",
    "            dItemGamma[i][k] += 2/N*userGamma[u][k]*diff\n",
    "    for u in userBiases: \n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "        for k in range(K):\n",
    "            dUserGamma[u][k] += 2/N*userGamma[u][k]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "        for k in range(K):\n",
    "            dItemGamma[i][k] += 2/N*itemGamma[i][k]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    for u in users:\n",
    "        dtheta += dUserGamma[u]\n",
    "    for i in items:\n",
    "        dtheta += dItemGamma[i]\n",
    "    return numpy.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean square error\n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions, labels)]\n",
    "    return sum(differences)/len(differences)\n",
    "# baseline\n",
    "alwaysPredictMean = [ratingMean for d in dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4796142779564334"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [d['star_rating'] for d in dataset]\n",
    "# Compute the accuracty of trivial baseline\n",
    "MSE(alwaysPredictMean, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 1.4796142779564334\n",
      "MSE = 1.4764397325863097\n",
      "MSE = 1.4787141438375289\n",
      "MSE = 1.4794090186282771\n",
      "MSE = 1.479570207519254\n",
      "MSE = 1.4796049432028695\n",
      "MSE = 1.479612306458805\n",
      "MSE = 1.4796138618447625\n",
      "MSE = 1.4796141901407405\n",
      "MSE = 1.4796142594298556\n",
      "MSE = 1.4796142740506226\n",
      "MSE = 1.4796142771472431\n",
      "MSE = 1.4796142778005967\n",
      "MSE = 1.4796142779238735\n",
      "MSE = 1.479614277945896\n",
      "MSE = 1.4796142779539028\n",
      "MSE = 1.4796142779559502\n",
      "MSE = 1.47961427795641\n",
      "MSE = 1.479614277956431\n",
      "MSE = 1.4796142779564334\n",
      "MSE = 1.4796142779564334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([4.25110277, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 0.0,\n",
       " {'grad': array([ 8.33042349e-13,  2.76558614e-06, -1.15881596e-05, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]),\n",
       "  'task': b'ABNORMAL_TERMINATION_IN_LNSRCH',\n",
       "  'funcalls': 21,\n",
       "  'nit': 0,\n",
       "  'warnflag': 2})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.optimize.fmin_l_bfgs_b(cost, [ratingMean] + [0.0]* (nUsers*(K+1)+nItems*(K+1)),\n",
    "                            derivative, args = (labels, 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
