{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias only model \n",
    " - Write down code for the gradient equations\n",
    " - Use gradient descent library to optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy\n",
    "import scipy.optimize\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/cnogueira/Documents/Development/Notebooks/study/week2/amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gzip.open(path, 'rt', encoding=\"utf8\")\n",
    "header = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = header.strip().split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for line in f: \n",
    "    fields = line.strip().split('\\t')\n",
    "    d = dict(zip(header, fields))\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d['helpful_votes'] = int(d['helpful_votes'])\n",
    "    d['total_votes'] = int(d['total_votes'])\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here i am creating two data structures:  \n",
    "#For each user, which itens did they consume (users per item), and\n",
    "#For each items, which users consumed that item (item per user)\n",
    "usersPerItem = defaultdict(set) #Ui\n",
    "itemsPerUser = defaultdict(set) #Iu\n",
    "itemNames = {}\n",
    "for d in dataset:\n",
    "    user, item = d['customer_id'], d['product_id']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    itemNames[item] = d['product_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "for d in dataset:\n",
    "    user, item = d['customer_id'], d['product_id']\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(dataset)\n",
    "nUsers = len(reviewsPerUser)\n",
    "nItems = len(reviewsPerItem)\n",
    "users = list(reviewsPerUser.keys())\n",
    "items = list(reviewsPerItem.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just to see if the algorithm is better to just predict the mean in terms of mean square error all the time\n",
    "ratingMean = sum([d['star_rating'] for d in dataset])/len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting\n",
    "    - Alpha and Betau/Betai (userbiases) are the parameters I will fit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial value of alpha is the mean reating to help the algo to convert qickly\n",
    "alpha = ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial valie of betai and betau is zerp\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prediction function is just the bias only model\n",
    "def prediction(user, item):\n",
    "    return alpha + userBiases[user] + itemBiases[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack function\n",
    "# The gradient descent library expects a single vector of parameters (theta) \n",
    "# On this function I am unpacking back to produce alpha and betau and betai\n",
    "\n",
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0] # Alpha is the first position on the vector\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1])) \n",
    "    # Start on position 1 and go until the rest of the users onwards to the rest of that vector\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function is also required by the library (is written on the notes)\n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta) # extract alpha, betai, betau\n",
    "    # Use those values to make predictions in the datapoints on the training set\n",
    "    predictions = [prediction(d['customer_id'], d['product_id']) for d in dataset]\n",
    "    cost = MSE(predictions, labels)\n",
    "    # Debugging\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    # Regularization\n",
    "    for u in userBiases:\n",
    "        cost *= lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivative function has a corresponding derivative term for each parameter\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta) # have alpha, betau for each user and betai for each item\n",
    "    N =  len(dataset)\n",
    "    # derivative for offset term alpha\n",
    "    dalpha = 0\n",
    "    # derivative for each user\n",
    "    dUserBiases = defaultdict(float)\n",
    "    # derivative for each item\n",
    "    dItemBiases = defaultdict(float)\n",
    "    # I iterate throught all the dataset once and update the derivates as I go\n",
    "    for d in dataset:\n",
    "        u,i = d['customer_id'], d['product_id']\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - d['star_rating']\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] +=  2/N*diff\n",
    "        dItemBiases[u] +=  2/N*diff\n",
    "    for u in userBiases: \n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    return numpy.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean square error\n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions, labels)]\n",
    "    return sum(differences)/len(differences)\n",
    "# baseline\n",
    "alwaysPredictMean = [ratingMean for d in dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4796142779564334"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [d['star_rating'] for d in dataset]\n",
    "# Compute the accuracty of trivial baseline\n",
    "MSE(alwaysPredictMean, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 1.4796142779564334\n",
      "MSE = 1.4764397325863097\n",
      "MSE = 1.4787141438375289\n",
      "MSE = 1.4794090186282771\n",
      "MSE = 1.479570207519254\n",
      "MSE = 1.4796049432028695\n",
      "MSE = 1.479612306458805\n",
      "MSE = 1.4796138618447625\n",
      "MSE = 1.4796141901407405\n",
      "MSE = 1.4796142594298556\n",
      "MSE = 1.4796142740506226\n",
      "MSE = 1.4796142771472431\n",
      "MSE = 1.4796142778005967\n",
      "MSE = 1.4796142779238735\n",
      "MSE = 1.479614277945896\n",
      "MSE = 1.4796142779539028\n",
      "MSE = 1.4796142779559502\n",
      "MSE = 1.47961427795641\n",
      "MSE = 1.479614277956431\n",
      "MSE = 1.4796142779564334\n",
      "MSE = 1.4796142779564334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([4.25110277, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " 0.0,\n",
       " {'grad': array([ 8.33042349e-13,  2.76558614e-06, -1.15881596e-05, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]),\n",
       "  'task': b'ABNORMAL_TERMINATION_IN_LNSRCH',\n",
       "  'funcalls': 21,\n",
       "  'nit': 0,\n",
       "  'warnflag': 2})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.optimize.fmin_l_bfgs_b(cost, [ratingMean] + [0.0]* (nUsers+nItems),\n",
    "                            derivative, args = (labels, 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
